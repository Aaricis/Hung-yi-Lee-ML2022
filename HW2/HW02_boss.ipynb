{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10801861,
          "sourceType": "datasetVersion",
          "datasetId": 6704380
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aaricis/Hung-yi-Lee-ML2022/blob/main/HW2/HW02_boss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework 2: Phoneme Classification**\n"
      ],
      "metadata": {
        "id": "OYlaRwNu7ojq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "* Solve a classification problem with deep neural networks (DNNs).\n",
        "* Understand recursive neural networks (RNNs).\n",
        "\n",
        "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
      ],
      "metadata": {
        "id": "A7DRC5V7_8A5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boss Bseline\n",
        "Score: 0.83055\n",
        "Private score: 0.83148\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "助教提示使用RNN模型，可以使用Pytorch的`nn.LSTM`、`nn.GRU`、`nn.RNN`等模型。\n",
        "\n",
        "|  模型    |  参数    |  acc    |\n",
        "| ---- | ---- | ---- |\n",
        "|  RNN    |   默认   |   0.445   |\n",
        "|  RNN    |   concat_nframes = 21 hidden_layers = 3 hidden_dim = 256 * 3 num_epoch = 5|  0.739    |\n",
        "|  RNN    |   concat_nframes = 21 hidden_layers = 4 hidden_dim = 256 * 3 num_epoch = 5|  0.743    |\n",
        "|  LSTM    |   concat_nframes = 21 hidden_layers = 3 hidden_dim = 256 * 3 num_epoch = 5|  0.744   |\n",
        "|  BiLSTM + MLP  |   concat_nframes = 61 hidden_layers = 6 hidden_dim = 256 * 4 num_epoch = 15|  0.82340    |\n",
        "|      |      |      |\n",
        "\n",
        "一开始尝试单纯的RNN和LSTM，都没有获得好的效果。后来尝试BiLSTM + MLP模型，并且显著增大各训练参数的值，就可以达到Boss Bseline了。一圈试下来，这个task就是“力大砖飞”，使劲增大输入数据维度和超参数就🆗了。\n"
      ],
      "metadata": {
        "id": "HPD8exnNyfDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have\n",
        "- `libriphone/train_split.txt`: training metadata\n",
        "- `libriphone/train_labels`: training labels\n",
        "- `libriphone/test_split.txt`: testing metadata\n",
        "- `libriphone/feat/train/*.pt`: training feature\n",
        "- `libriphone/feat/test/*.pt`:  testing feature\n",
        "\n",
        "after running the following block.\n",
        "\n",
        "> **Notes: if the google drive link is dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2023spring-hw2/data) and upload it to the workspace.**\n"
      ],
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main link\n",
        "!wget -O libriphone.zip \"https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip\"\n",
        "\n",
        "# Backup Link 0\n",
        "# !pip install --upgrade gdown\n",
        "# !gdown --id '1o6Ag-G3qItSmYhTheX6DYiuyNzWyHyTc' --output libriphone.zip\n",
        "\n",
        "# Backup link 1\n",
        "# !pip install --upgrade gdown\n",
        "# !gdown --id '1R1uQYi4QpX0tBfUWt2mbZcncdBsJkxeW' --output libriphone.zip\n",
        "\n",
        "# Backup link 2\n",
        "# !wget -O libriphone.zip \"https://www.dropbox.com/s/wqww8c5dbrl2ka9/libriphone.zip?dl=1\"\n",
        "\n",
        "# Backup link 3\n",
        "# !wget -O libriphone.zip \"https://www.dropbox.com/s/p2ljbtb2bam13in/libriphone.zip?dl=1\"\n",
        "\n",
        "!unzip -q libriphone.zip\n",
        "!ls libriphone"
      ],
      "metadata": {
        "id": "OzkiMEcC3Foq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:06:21.003313Z",
          "iopub.execute_input": "2025-02-20T08:06:21.003627Z",
          "iopub.status.idle": "2025-02-20T08:06:39.941845Z",
          "shell.execute_reply.started": "2025-02-20T08:06:21.003588Z",
          "shell.execute_reply": "2025-02-20T08:06:39.940961Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0363bb06-3a9b-4a82-d44f-fae60e864a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-21 07:48:24--  https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/463868124/343908dd-b2e4-4b8e-b7d6-7f0f040179ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250221%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250221T074825Z&X-Amz-Expires=300&X-Amz-Signature=26618cd3966cc28b00d3ad84fd277be1db1719b3da89e2cb8725440652df66af&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dlibriphone.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-21 07:48:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/463868124/343908dd-b2e4-4b8e-b7d6-7f0f040179ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250221%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250221T074825Z&X-Amz-Expires=300&X-Amz-Signature=26618cd3966cc28b00d3ad84fd277be1db1719b3da89e2cb8725440652df66af&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dlibriphone.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 478737370 (457M) [application/octet-stream]\n",
            "Saving to: ‘libriphone.zip’\n",
            "\n",
            "libriphone.zip      100%[===================>] 456.56M  37.6MB/s    in 13s     \n",
            "\n",
            "2025-02-21 07:48:39 (34.9 MB/s) - ‘libriphone.zip’ saved [478737370/478737370]\n",
            "\n",
            "feat  test_split.txt  train_labels.txt\ttrain_split.txt\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Utility Functions\n",
        "**Fixes random number generator seeds for reproducibility.**"
      ],
      "metadata": {
        "id": "pADUiYODJE1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def same_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "BsZKgBZQJjaE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T07:55:26.050464Z",
          "iopub.execute_input": "2025-02-20T07:55:26.050675Z",
          "iopub.status.idle": "2025-02-20T07:55:29.222953Z",
          "shell.execute_reply.started": "2025-02-20T07:55:26.050654Z",
          "shell.execute_reply": "2025-02-20T07:55:29.222018Z"
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
        "\n",
        "A phoneme may span several frames and is dependent to past and future frames. \\\n",
        "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
        "\n",
        "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
      ],
      "metadata": {
        "id": "_L_4anls8Drv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_feat(path):\n",
        "    feat = torch.load(path)\t# 导入音频文件\n",
        "    return feat\n",
        "\n",
        "def shift(x, n):\n",
        "    # 平移数据\n",
        "    if n < 0:\n",
        "        left = x[0].repeat(-n, 1)\n",
        "        right = x[:n]\n",
        "    elif n > 0:\n",
        "        right = x[-1].repeat(n, 1)\n",
        "        left = x[n:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return torch.cat((left, right), dim=0)\n",
        "\n",
        "def concat_feat(x, concat_n):\n",
        "    assert concat_n % 2 == 1 # n must be odd\n",
        "    if concat_n < 2:\n",
        "        return x\n",
        "    seq_len, feature_dim = x.size(0), x.size(1)\n",
        "    x = x.repeat(1, concat_n)\n",
        "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
        "    mid = (concat_n // 2)\n",
        "    for r_idx in range(1, mid+1):\n",
        "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "\n",
        "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, random_seed=1213):\n",
        "    class_num = 41 # NOTE: pre-computed, should not need change\n",
        "\n",
        "    if split == 'train' or split == 'val':\n",
        "        mode = 'train'\n",
        "    elif split == 'test':\n",
        "        mode = 'test'\n",
        "    else:\n",
        "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "    label_dict = {}\n",
        "    if mode == 'train':\n",
        "        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "\n",
        "        # split training and validation data\n",
        "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
        "        random.seed(random_seed)\n",
        "        random.shuffle(usage_list)\n",
        "        train_len = int(len(usage_list) * train_ratio)\n",
        "        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
        "\n",
        "    elif mode == 'test':\n",
        "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
        "\n",
        "    usage_list = [line.strip('\\n') for line in usage_list]\n",
        "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "    max_len = 3000000\n",
        "    X = torch.empty(max_len, 39 * concat_nframes)\n",
        "    if mode == 'train':\n",
        "        y = torch.empty(max_len, dtype=torch.long)\n",
        "\n",
        "    idx = 0\n",
        "    for i, fname in tqdm(enumerate(usage_list)):\n",
        "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "        cur_len = len(feat)\n",
        "        feat = concat_feat(feat, concat_nframes)\n",
        "        if mode == 'train':\n",
        "            label = torch.LongTensor(label_dict[fname])\n",
        "\n",
        "        X[idx: idx + cur_len, :] = feat\n",
        "        if mode == 'train':\n",
        "            y[idx: idx + cur_len] = label\n",
        "\n",
        "        idx += cur_len\n",
        "\n",
        "    X = X[:idx, :]\n",
        "    if mode == 'train':\n",
        "        y = y[:idx]\n",
        "\n",
        "    print(f'[INFO] {split} set')\n",
        "    print(X.shape)\n",
        "    if mode == 'train':\n",
        "        print(y.shape)\n",
        "        return X, y\n",
        "    else:\n",
        "        return X"
      ],
      "metadata": {
        "id": "IJjLT8em-y9G",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:14:15.754659Z",
          "iopub.execute_input": "2025-02-20T08:14:15.755063Z",
          "iopub.status.idle": "2025-02-20T08:14:15.768264Z",
          "shell.execute_reply.started": "2025-02-20T08:14:15.755036Z",
          "shell.execute_reply": "2025-02-20T08:14:15.767377Z"
        }
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "us5XW_x6udZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LibriDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = X\n",
        "        if y is not None:\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ],
      "metadata": {
        "id": "Fjf5EcmJtf4e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:14:22.578675Z",
          "iopub.execute_input": "2025-02-20T08:14:22.579002Z",
          "iopub.status.idle": "2025-02-20T08:14:22.584231Z",
          "shell.execute_reply.started": "2025-02-20T08:14:22.578978Z",
          "shell.execute_reply": "2025-02-20T08:14:22.583397Z"
        }
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "Feel free to modify the structure of the model."
      ],
      "metadata": {
        "id": "IRqKNvNZwe3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 双向LSTM"
      ],
      "metadata": {
        "id": "MTE7dZbvW7rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # TODO: apply batch normalization and dropout for strong baseline.\n",
        "        # Reference: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html (batch normalization)\n",
        "        #       https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html (dropout)\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.ReLU(),\n",
        "            # 在此处增加 nn.Dropout()\n",
        "            nn.Dropout(p=0.15)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# TODO: 做 Boss baseline 再取消注释\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        # TODO: 此时模型超参数在这里修改\n",
        "        # Create BiLSTM\n",
        "        self.input_size = 39    # 这一项是RNN的\"input_dim\"，RNN需要对\"单\"个数据进行处理\n",
        "        self.hidden_size = 512  # 这一项是RNN的\"hidden_dim\"\n",
        "        self.num_layers = 6     # 这一项是RNN的\"hidden_layers\"\n",
        "        self.rnn = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True, dropout=0.3, bidirectional=True)\n",
        "\n",
        "        # 后接全连接层\n",
        "        self.fc = nn.Sequential(\n",
        "            # 修改成 2 * self.hidden_size 的原因是因为LSTM()中的bidirectional设置为了True，这表示使用Bi（双向）LSTM模型，所以需要修改输入维度以匹配\n",
        "            BasicBlock(2 * self.hidden_size, hidden_dim),\n",
        "            # 在函数的调用中，一个 * 表示将一个序列展开为单独的位置参数，这一行代码是列表推导，最终的表现是重复生成多个 hidden layer\n",
        "            #（原来的整段代码实际上生成了 hidden_layers+1 个隐藏层，所以我修改了一下代码，让其符合定义）\n",
        "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers-1)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 通过RNN层，得到输出和最后一个隐藏状态，注意输出的shape\n",
        "        # x.shape: (batch_size, seq_len, RNN_input_size)\n",
        "        x, _ = self.rnn(x)  # => (batch_size, seq_len, RNN_hidden_size)\n",
        "\n",
        "        # 取最后一个时间步的输出作为分类的输入\n",
        "        x = x[:, -1]        # => (batch_size, RNN_hidden_size)\n",
        "\n",
        "        # 通过线性层，得到最终的分类结果\n",
        "        x = self.fc(x)      # => (batch_size, labels)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:14:28.046310Z",
          "iopub.execute_input": "2025-02-20T08:14:28.046628Z",
          "iopub.status.idle": "2025-02-20T08:14:28.054043Z",
          "shell.execute_reply.started": "2025-02-20T08:14:28.046604Z",
          "shell.execute_reply": "2025-02-20T08:14:28.053023Z"
        },
        "id": "S_d6zMTsW7rR"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameters"
      ],
      "metadata": {
        "id": "TlIq8JeqvvHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data prarameters\n",
        "# TODO: change the value of \"concat_nframes\" for medium baseline\n",
        "concat_nframes = 61 #21, 61      # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
        "train_ratio = 0.95           # the ratio of data used for training, the rest will be used for validation\n",
        "\n",
        "# Training parameters\n",
        "seed = 1213                  # random seed\n",
        "batch_size = 512             # batch size\n",
        "num_epoch = 5 # 15               # the number of training epoch\n",
        "learning_rate =  1e-3        # learning rate\n",
        "model_path = './model.ckpt'  # the path where the checkpoint will be saved\n",
        "\n",
        "# Model parameters\n",
        "# TODO: change the value of \"hidden_layers\" or \"hidden_dim\" for medium baseline\n",
        "input_dim = 39 * concat_nframes  # the input dim of the model, you should not change the value\n",
        "hidden_layers = 6            # the number of hidden layers\n",
        "hidden_dim = 1024 #512            # the hidden dim\n",
        "\n",
        "''' 以下是为了完成 report 所添加的代码 '''\n",
        "# TODO: 完成 report 后注释下面所有代码\n",
        "# 提前输出模型参数数量，以便调整网络架构\n",
        "# total_params = (\n",
        "#     (input_dim+1) * hidden_dim +\n",
        "#     (hidden_dim + 1) * hidden_dim * (hidden_layers - 1) +\n",
        "#     (hidden_dim + 1) * 41\n",
        "# )\n",
        "# print(f'Total params: {total_params}')\n",
        "\n",
        "# def get_dest_dim(input_dim, output_dim, hidden_layers, dest_hidden_layers, hidden_dim):\n",
        "#     '''获取目标网络隐藏层的维度（总参数量接近于原网络）'''\n",
        "#     # 计算一元二次方程的系数 a,b,c\n",
        "#     a = dest_hidden_layers - 1  # a = l_d - 1\n",
        "#     b = input_dim + output_dim + dest_hidden_layers  #  b = i + o + l_d\n",
        "#     c = - (hidden_layers - 1) * (hidden_dim ** 2) - (input_dim + output_dim + hidden_layers) * hidden_dim  # c = - (l - 1) * (d ** 2) - (i + o + l) * d\n",
        "\n",
        "#     # 计算分子中的平方根部分，即 b^2-4ac\n",
        "#     sqrt_part = (b ** 2) - 4 * a * c\n",
        "\n",
        "#     # 计算两个解，一个是加号，一个是减号，即(-b±√(b^2-4ac))/(2a)\n",
        "#     d_d_plus = (-b + sqrt_part**(0.5)) / (2 * a)\n",
        "#     d_d_minus = (-b - sqrt_part**(0.5)) / (2 * a)\n",
        "\n",
        "#     # 返回两个解的元组\n",
        "#     return (d_d_plus, d_d_minus)\n",
        "\n",
        "# # 设置你想要的目标网络隐藏层数量\n",
        "# dest_hidden_layers = 2\n",
        "\n",
        "# # 获取对应的维数\n",
        "# dest_hidden_dim, _ = get_dest_dim(input_dim, 41, hidden_layers, dest_hidden_layers, hidden_dim)\n",
        "# print(f\"若将隐藏层网络层数改为: {dest_hidden_layers}，则维数应当改为: {round(dest_hidden_dim)}\",)"
      ],
      "metadata": {
        "id": "iIHn79Iav1ri",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:14:34.525568Z",
          "iopub.execute_input": "2025-02-20T08:14:34.525913Z",
          "iopub.status.idle": "2025-02-20T08:14:34.532322Z",
          "shell.execute_reply.started": "2025-02-20T08:14:34.525885Z",
          "shell.execute_reply": "2025-02-20T08:14:34.531519Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85b51da3-c342-4276-fc95-17d1e9f339a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 以下是为了完成 report 所添加的代码 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader"
      ],
      "metadata": {
        "id": "IIUFRgG5yoDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import gc\n",
        "\n",
        "same_seeds(seed)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# Preprocess data\n",
        "train_X, train_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
        "val_X, val_y = preprocess_data(split='val', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
        "\n",
        "# Get dataset\n",
        "train_set = LibriDataset(train_X, train_y)\n",
        "val_set = LibriDataset(val_X, val_y)\n",
        "\n",
        "# Remove raw feature to save memory\n",
        "del train_X, train_y, val_X, val_y\n",
        "gc.collect()\n",
        "\n",
        "# Get dataloader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "c1zI3v5jyrDn",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:14:42.873417Z",
          "iopub.execute_input": "2025-02-20T08:14:42.873779Z",
          "iopub.status.idle": "2025-02-20T08:15:16.302674Z",
          "shell.execute_reply.started": "2025-02-20T08:14:42.873746Z",
          "shell.execute_reply": "2025-02-20T08:15:16.302012Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48b16cd-ac79-4b57-b87e-d22382b43b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n",
            "[Dataset] - # phone classes: 41, number of utterances for train: 4071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]<ipython-input-3-b47e0bf89eaa>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\t# 导入音频文件\n",
            "4071it [00:22, 178.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] train set\n",
            "torch.Size([2510111, 2379])\n",
            "torch.Size([2510111])\n",
            "[Dataset] - # phone classes: 41, number of utterances for val: 215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "215it [00:01, 179.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] val set\n",
            "torch.Size([134047, 2379])\n",
            "torch.Size([134047])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "pwWH1KIqzxEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## For plotting learning curve\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter() # Tensorboard 画图，结果存储在 ./runs 中\n",
        "\n",
        "RESUME = True  # 是否导入模型继续跑（在你不小心中断了内核后）\n",
        "\n",
        "# Create a model, and put it on the device specified.\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "\n",
        "if RESUME:\n",
        "    # model.load_state_dict(torch.load(\"../input/hw2-model/model.ckpt\", map_location='cuda')) # kaggle\n",
        "    model.load_state_dict(torch.load(\"/content/model.ckpt\", map_location='cuda'))\n",
        "\n",
        "# Define a loss function, and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Create a learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.8, patience=5, threshold=0.05) # 5 轮没有优化（增长率 < threshold)就令 lr *= factor\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # ---------- Training ----------\n",
        "    # Make sure the model is in train mode before training.\n",
        "    model.train()\n",
        "\n",
        "    for i, batch in enumerate(tqdm(train_loader)):\n",
        "\n",
        "        # A batch consists of features data and corresponding labels.\n",
        "        features, labels = batch  # feature.shape: (batch_size, seq_len * input_size)\n",
        "\n",
        "        # Forward the data. (Make sure data and model are on the same device.)\n",
        "        # features = features.to(device)\n",
        "        # TODO: RNN则取消注释下行\n",
        "        features = features.view(-1, concat_nframes, 39).to(device) # feature.shape: (batch_size, seq_len, input_size)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(features) # (batch_size, labels)\n",
        "\n",
        "        # Calculate the cross-entropy loss.\n",
        "        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Gradients stored in the parameters in the previous step should be cleared out first.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute the gradients for parameters.\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters with computed gradients.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get the index of the class with the highest probability\n",
        "        _, train_pred = torch.max(outputs, 1)\n",
        "\n",
        "        # Compute the accuracy for current batch.\n",
        "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # ---------- Validation ----------\n",
        "    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
        "    model.eval()\n",
        "\n",
        "    # We don't need gradient in validation.\n",
        "    # Using torch.no_grad() accelerates the forward process.\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(val_loader)):\n",
        "            features, labels = batch\n",
        "            # features = features.to(device)\n",
        "            # TODO: RNN则取消注释下行\n",
        "            features = features.view(-1, concat_nframes, 39).to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(features)\n",
        "\n",
        "            # We can still compute the loss (but not the gradient).\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Get the index of the class with the highest probability\n",
        "            _, val_pred = torch.max(outputs, 1)\n",
        "\n",
        "            # Compute the accuracy for current batch.\n",
        "            val_acc += (val_pred.cpu() == labels.cpu()).sum().item()\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    # Record the accuracy and lr.\n",
        "    writer.add_scalar('Acc/train', train_acc/len(train_set), epoch)\n",
        "    writer.add_scalar('Acc/valid', val_acc/len(val_set), epoch)\n",
        "    writer.add_scalar('lr', optimizer.state_dict()['param_groups'][0]['lr'], epoch)\n",
        "\n",
        "    # Print the information.\n",
        "    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n",
        "\n",
        "    # If the model improves, save a checkpoint at this epoch\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f'saving model with acc {best_acc/len(val_set):.5f}')\n",
        "\n",
        "    print(f\"{epoch+1} lr: {optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
        "\n",
        "    # Update learning rate based on best loss\n",
        "    # Modify step() according to your scheduler\n",
        "    scheduler.step(val_acc/len(val_set))\n",
        "\n",
        "print(f'saving model with acc {best_acc/len(val_set):.5f}')\n"
      ],
      "metadata": {
        "id": "CdMWsBs7zzNs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:15:21.943638Z",
          "iopub.execute_input": "2025-02-20T08:15:21.943968Z",
          "iopub.status.idle": "2025-02-20T08:15:57.979416Z",
          "shell.execute_reply.started": "2025-02-20T08:15:21.943945Z",
          "shell.execute_reply": "2025-02-20T08:15:57.978138Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ce42ea-991b-4dee-83d4-d9ce23bd2abd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-ca26ea5e6eb4>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"/content/model.ckpt\", map_location='cuda'))\n",
            "100%|██████████| 4903/4903 [08:57<00:00,  9.11it/s]\n",
            "100%|██████████| 262/262 [00:09<00:00, 27.65it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/005] Train Acc: 0.93913 Loss: 0.17080 | Val Acc: 0.81962 loss: 0.99753\n",
            "saving model with acc 0.81962\n",
            "1 lr: 0.001\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4903/4903 [08:56<00:00,  9.14it/s]\n",
            "100%|██████████| 262/262 [00:09<00:00, 28.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[002/005] Train Acc: 0.93795 Loss: 0.17415 | Val Acc: 0.82095 loss: 0.99449\n",
            "saving model with acc 0.82095\n",
            "2 lr: 0.001\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4903/4903 [08:56<00:00,  9.14it/s]\n",
            "100%|██████████| 262/262 [00:09<00:00, 28.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[003/005] Train Acc: 0.93915 Loss: 0.17005 | Val Acc: 0.82340 loss: 1.00099\n",
            "saving model with acc 0.82340\n",
            "3 lr: 0.001\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4903/4903 [08:56<00:00,  9.14it/s]\n",
            "100%|██████████| 262/262 [00:09<00:00, 28.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[004/005] Train Acc: 0.93951 Loss: 0.16911 | Val Acc: 0.82150 loss: 0.96015\n",
            "4 lr: 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4903/4903 [08:56<00:00,  9.13it/s]\n",
            "100%|██████████| 262/262 [00:09<00:00, 27.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[005/005] Train Acc: 0.74986 Loss: 0.87042 | Val Acc: 0.68219 loss: 1.19360\n",
            "5 lr: 0.001\n",
            "saving model with acc 0.82340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=./runs/"
      ],
      "metadata": {
        "id": "5uiXX1ZnW7rW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "del train_set, val_set\n",
        "del train_loader, val_loader\n",
        "gc.collect()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-07T10:18:47.085697Z",
          "start_time": "2023-04-07T10:18:47.065320Z"
        },
        "id": "ab33MxosWLmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0616990-2f9f-4a3f-d57b-d634b8367748"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "Create a testing dataset, and load model from the saved checkpoint."
      ],
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes)\n",
        "test_set = LibriDataset(test_X, None)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "VOG1Ou0PGrhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc6fa97-a875-48f2-c3a9-bf2a229350dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for test: 1078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]<ipython-input-3-b47e0bf89eaa>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\t# 导入音频文件\n",
            "1078it [00:06, 164.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] test set\n",
            "torch.Size([646268, 2379])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "id": "ay0Fu8Ovkdad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f437411b-3689-42c5-cc0c-41a3a996453d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-f7b7612de35f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make prediction."
      ],
      "metadata": {
        "id": "zp-DV1p4r7Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.array([], dtype=np.int32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader)):\n",
        "        features = batch\n",
        "        # features = features.to(device)\n",
        "        features = features.view(-1, concat_nframes, 39).to(device)\n",
        "\n",
        "        outputs = model(features)\n",
        "\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n"
      ],
      "metadata": {
        "id": "84HU5GGjPqR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc44c9a7-8e96-4ac1-a56f-64644d384806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1263/1263 [00:42<00:00, 29.71it/s]\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ],
      "metadata": {
        "id": "wyZqy40Prz0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(pred):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ],
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YIBz71I8W7rZ"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}